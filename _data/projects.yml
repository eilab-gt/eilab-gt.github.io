- name: Automated Story Generation
  description: >
    Humans use storytelling to entertain, share experiences, educate, 
    and to facilitate social bonding. For an intelligent system to be 
    unable to generate a story limits its ability to interact with humans 
    in naturalistic ways. Automated Story Generation, in particular, has been a 
    grand challenge in artificial intelligence, requiring a system to construct 
    a sequence of sentences that can be read and understood as a story.
    This research seeks fundamental advances in automated story generation and
    related fields such as machine reading, narrative understanding, and 
    commonsense reasoning.
  pubs:
    - id: riedljair2010
      context: Symbolic planning for automated story generation.
    - id: martinaaai2018
      context: Foundational work on neural story generation.
    - id: tambwekarijcai2019
      context: Goal-directed controllability of neural story generation systems.
- name: Text Adventure Games
  description: >
    Natural language communication can be used to affect change in the real world.   
    Text adventure games, in which players must make sense of the world through text 
    descriptions and declare  actions through natural language, can provide a stepping 
    stone toward more real-world environments where agents must communicate to 
    understand the state of the world and indirectly affect change inthe world.  
    Text adventure games are also, by some metrics, harder than video games such
    as StarCraft. For example the classic game <strong>Zork</strong> has never been beaten.
    We seek up develop new reinforcement learning agents that can reason about 
    and solve language-based tasks involving long-term causal dependencies.
  pubs: 
    - id: Ammanabrolu2019
      context: >
        We introduce KG-DQN, a method for planing text-adventure games using 
        knowledge graphs as a means of handling partial observability and
        combinatorially large action spaces 
    - id: ammanabrolu2020Graph
      context: We improve on KG-DQN results with KG-A2C.
    - id: ammanabrolu2020avoid 
      context: >
        We show that large language models can be fine-tuned to generate 
        knowledge graphs, improving sample efficiency. We further show
        that an agent that learns the structure of the game can set a new
        state of the art in Zork (specifically passing the Grue).
- name: Explainable AI
  description: >
    AI systems are increasingly deployed in high-stakes setting that affect 
    non-technical end-users. Explanations can help users understand what an AI 
    system is doing and the decisions it makes. However, we don't understand 
    the human factors of
    explanations and how they create trust and improve the space of actions and
    remediations available to users. In this project we seek to understand how
    explanations affect users and how to design better explanation generation 
    systems.
  pubs:
    - id: harrisonaies2018
      context: Introducing the concept of 'Rationale Generation'
    - id: ehsaniui2019
      context: Experiments on the human factors of rationale generation
    - id: Ehsan2021ExpandingET
      context: >
        Explanation generation systems are parts of socio-technical systems.
        We explore the effects of explanations on teams.
- name: Value Alignment
  description: >
    Value alignmentis a property of an intelligent agent indicating that it can  
    only pursue goals and activities that are beneficial to humans. How do we
    teach AI systems values? We introduce **normative alignment**, the concept
    that an agent should adhere to social and cultural norms. We present techniques
    for teaching AI systems sociocultural norms and biasing agent behavior (whether
    a generative language model or a reinforcement learning agent) toward 
    agreed upon norms for a particular society.
  pubs: 
    - id: Frazier2020LearningNF
      context: >
        We introduce a neural model that can classify textual descriptions of
        behavior as normative. The model achieves high zero-shot transfer across
        domains.
    - id: Peng2020ReducingNT
      context: >
        Using the above normative classifier, we can use reinforcement learning to
        reduce the amount of non-normative behavior descriptions generated by
        large pre-trained language models, making them safer.
    - id: NahianTraining2021 
      context: >
        We show how a normative classifier can be introduced as a source of
        reward in reinforcement learning agents, resulting in value aligned
        agents that can learn altruistic behavior even while pursing task rewards.
- name: Novelty Adaptation
  description: >
    Deep reinforcement learning systems have been demonstrated to be very effective
    at playing games, but also brittle to novelty. For example when the rules of a
    game change (or under board game
    'house rules'), a pre-trained policy model may no longer suffice,
    requiring sample-inefficient trial-and-error learning to update the 
    policy model. In this work, we seek to develop algorithms that learn the "rules
    of the game", detect when the rules change, and rapidly adapt to the novelty.

